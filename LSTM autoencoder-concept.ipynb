{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model ,models, layers, optimizers, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction LSTM Autoencoder\n",
    "\n",
    "The simplest LSTM autoencoder is one that learns to reconstruct each input sequence.\n",
    "For these demonstrations, we will use a dataset of one sample of nine time steps and one feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "sequence = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(sequence)\n",
    "sequence = sequence.reshape((1, n_in, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20262384cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(100, activation='relu', input_shape=(n_in, 1)))\n",
    "model.add(layers.RepeatVector(n_in))\n",
    "model.add(layers.LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10559099],\n",
       "        [0.20217314],\n",
       "        [0.30041453],\n",
       "        [0.39952287],\n",
       "        [0.49908453],\n",
       "        [0.5987617 ],\n",
       "        [0.69832975],\n",
       "        [0.7991052 ],\n",
       "        [0.9024458 ]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "yhat = model.predict(sequence)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction LSTM Autoencoder\n",
    "\n",
    "We can modify the reconstruction LSTM Autoencoder to instead predict the next step in the sequence.\n",
    "In the case of our small contrived problem, we expect the output to be the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "seq_in = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x202703bbe10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model \n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(100, activation='relu', input_shape=(n_in, 1)))\n",
    "model.add(layers.RepeatVector(n_out))\n",
    "model.add(layers.LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(seq_in, seq_out, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.16683361],\n",
       "        [0.2898971 ],\n",
       "        [0.403169  ],\n",
       "        [0.5089176 ],\n",
       "        [0.6094323 ],\n",
       "        [0.7060289 ],\n",
       "        [0.7997408 ],\n",
       "        [0.89148134]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "yhat = model.predict(seq_in)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite LSTM Autoencoder\n",
    "\n",
    "Finally, we can create a composite LSTM Autoencoder that has a single encoder and two decoders, one for reconstruction and one for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "seq_in = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2027597f7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define encoder\n",
    "visible = layers.Input(shape=(n_in, 1))\n",
    "encoder = layers.LSTM(100, activation='relu')(visible)\n",
    "# define reconstruct decoder\n",
    "decoder1 = layers.RepeatVector(n_in)(encoder)\n",
    "decoder1 = layers.LSTM(100, activation='relu', return_sequences=True)(decoder1)\n",
    "decoder1 = layers.TimeDistributed(layers.Dense(1))(decoder1)\n",
    "# define predict decoder\n",
    "decoder2 = layers.RepeatVector(n_out)(encoder)\n",
    "decoder2 = layers.LSTM(100, activation='relu', return_sequences=True)(decoder2)\n",
    "decoder2 = layers.TimeDistributed(layers.Dense(1))(decoder2)\n",
    "# concat model\n",
    "model = Model(inputs=visible, outputs=[decoder1, decoder2])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# utils.plot_model(model, show_shapes=True, to_file='composite_lstm_autoencoder.png')\n",
    "\n",
    "# fit model \n",
    "model.fit(seq_in, [seq_in, seq_out], epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.10127164],\n",
       "         [0.19949059],\n",
       "         [0.29943317],\n",
       "         [0.39987874],\n",
       "         [0.50023794],\n",
       "         [0.60028654],\n",
       "         [0.7000689 ],\n",
       "         [0.79983366],\n",
       "         [0.89999163]]], dtype=float32), array([[[0.19868489],\n",
       "         [0.30206183],\n",
       "         [0.3981459 ],\n",
       "         [0.4989811 ],\n",
       "         [0.600592  ],\n",
       "         [0.7013527 ],\n",
       "         [0.80077535],\n",
       "         [0.8988221 ]]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "yhat = model.predict(seq_in)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Standalone LSTM Encoder\n",
    "\n",
    "Regardless of the method chosen (reconstruction, prediction, or composite), once the autoencoder has been fit, the decoder can be removed and the encoder can be kept as a standalone model.\n",
    "\n",
    "The encoder can then be used to transform input sequences to a fixed length encoded vector.\n",
    "\n",
    "We can do this by creating a new model that has the same inputs as our original model, and outputs directly from the end of encoder model, before the RepeatVector layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "seq_in = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(layers.RepeatVector(n_in))\n",
    "model.add(layers.LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(layers.TimeDistributed(layers.Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)\n",
    "# connect the encoder LSTM as the output layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[0].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "[[0.00362787 0.         0.         0.08213381 0.08537362 0.0432427\n",
      "  0.         0.         0.01888101 0.         0.0003575  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.13369964\n",
      "  0.         0.03780872 0.03652276 0.08293831 0.         0.\n",
      "  0.05843791 0.07145996 0.         0.         0.03048124 0.08965353\n",
      "  0.         0.06230371 0.         0.08197825 0.         0.\n",
      "  0.         0.01264344 0.06010371 0.06315333 0.         0.\n",
      "  0.         0.         0.         0.10529362 0.08009851 0.09936683\n",
      "  0.         0.09390101 0.         0.         0.07640777 0.\n",
      "  0.         0.05778015 0.         0.         0.12206501 0.\n",
      "  0.         0.         0.         0.         0.         0.11213464\n",
      "  0.         0.04824944 0.         0.14111644 0.07408844 0.\n",
      "  0.         0.         0.         0.         0.06998165 0.\n",
      "  0.         0.0079558  0.08975866 0.         0.         0.\n",
      "  0.09860425 0.         0.         0.         0.03271302 0.\n",
      "  0.02801727 0.0917893  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "yhat = model.predict(sequence)\n",
    "print(yhat.shape)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#What is the difference between 'return_sequences=Ture' and 'RepeatVector'?\n",
    "- \"<code>return_sequence=True</code>\" returns all the outputs the encoder observed in the past.\n",
    "- \"<code>RepeatVector</code>\" repeats the very last output of the encoder\n",
    "<img src='https://i.stack.imgur.com/LNXjF.jpg'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#What is the TimeDistributed layers?\n",
    "- Using TimeDistributed layer\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxOTA3MTlfMTQ0/MDAxNTYzNDk5MDIwNjk0.Ko1jG4ematFNFGaS7dFJqJCKoyIVhLXsSLsUNWzadukg.laQainx0gqsofM7EmEi-A5POshd0OkX4yC4Ay0ZeOkwg.GIF.chunjein/2-1.gif?type=w2\">\n",
    "\n",
    "- Not using TimeDistributed layer(= return_sequences=True)\n",
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxOTA3MTlfMjEz/MDAxNTYzNDk5MzU3MTU3.CvAWXC9qs5JiguevobzkDPmOggpTNGJNhNJvbh7bEy0g.uTUc7Hbx-UIXsP3tRZVMGFDj_7wv4YVwokvwkIwKlgwg.GIF.chunjein/2-2.gif?type=w2\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
